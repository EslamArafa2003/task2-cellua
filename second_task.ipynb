{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu5ZVZaTgnKK",
        "outputId": "01896ca2-46dc-4cf8-c7dd-bb3f01fa1014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/MyDrive/Teeth_Dataset2.zip'\n",
        "extract_dir = '/content/Teeth DataSet/'\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(\"Files extracted to:\", extract_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kAyWpjsr8lT",
        "outputId": "996d4489-d189-4375-f80c-4035709b9f39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: /content/Teeth DataSet/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/Teeth DataSet/Teeth_Dataset/Training'\n",
        "validation_dir = '/content/Teeth DataSet/Teeth_Dataset/Validation'\n",
        "test_dir = '/content/Teeth DataSet/Teeth_Dataset/Testing'\n",
        "# Image dimensions and batch size\n",
        "IMG_HEIGHT = 224  # EfficientNetB0 expects 224x224 images\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "O1IiU4KltuOH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Data Augmentation and Normalization"
      ],
      "metadata": {
        "id": "tXLRdjvHuKlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    shear_range=0.4,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load data\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_data_gen = validation_image_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrIDOK39uFYU",
        "outputId": "6b08737f-8a6c-4d56-f324-749aa3af7331"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3087 images belonging to 7 classes.\n",
            "Found 1028 images belonging to 7 classes.\n",
            "Found 1028 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Model Architecture and Training"
      ],
      "metadata": {
        "id": "ky-YL3rKwdfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 model with pre-trained\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(train_data_gen.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNzksZ1wZv-",
        "outputId": "1bee7009-8fc3-464b-a849-ecac50529b58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "1_UoFO5nwl9y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit( train_data_gen, epochs=30, steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
        "    validation_data=val_data_gen, validation_steps=val_data_gen.samples // BATCH_SIZE, callbacks=[lr_scheduler, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cso59f4I0D0V",
        "outputId": "8b2f663a-6fc8-4dd4-a1cc-b03695e6db28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 584ms/step - accuracy: 0.1639 - loss: 5.1973 - val_accuracy: 0.1758 - val_loss: 4.0147 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/96\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.1562 - loss: 4.0981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.1562 - loss: 4.0981 - val_accuracy: 0.0000e+00 - val_loss: 4.2446 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 479ms/step - accuracy: 0.1766 - loss: 3.8874 - val_accuracy: 0.2100 - val_loss: 3.3129 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0938 - loss: 3.4288 - val_accuracy: 0.0000e+00 - val_loss: 3.4370 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 479ms/step - accuracy: 0.1675 - loss: 3.2637 - val_accuracy: 0.2295 - val_loss: 2.9669 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 2.8965 - val_accuracy: 0.5000 - val_loss: 2.8473 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 480ms/step - accuracy: 0.1614 - loss: 2.9554 - val_accuracy: 0.2275 - val_loss: 2.8029 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.1562 - loss: 2.8432 - val_accuracy: 0.2500 - val_loss: 2.7862 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 472ms/step - accuracy: 0.1679 - loss: 2.8060 - val_accuracy: 0.1934 - val_loss: 2.7103 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.1875 - loss: 2.7150 - val_accuracy: 0.2500 - val_loss: 2.6825 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 478ms/step - accuracy: 0.1704 - loss: 2.7163 - val_accuracy: 0.1758 - val_loss: 2.6550 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.2188 - loss: 2.6025 - val_accuracy: 0.0000e+00 - val_loss: 2.7528 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 478ms/step - accuracy: 0.1748 - loss: 2.6597 - val_accuracy: 0.2031 - val_loss: 2.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 2.6129 - val_accuracy: 0.5000 - val_loss: 2.4902 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 486ms/step - accuracy: 0.1708 - loss: 2.6236 - val_accuracy: 0.1982 - val_loss: 2.5736 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.1562 - loss: 2.6299 - val_accuracy: 0.0000e+00 - val_loss: 2.6630 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 477ms/step - accuracy: 0.1806 - loss: 2.5966 - val_accuracy: 0.2139 - val_loss: 2.5567 - learning_rate: 5.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.1562 - loss: 2.6043 - val_accuracy: 0.0000e+00 - val_loss: 2.5298 - learning_rate: 5.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 473ms/step - accuracy: 0.1711 - loss: 2.5750 - val_accuracy: 0.2090 - val_loss: 2.5465 - learning_rate: 2.5000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze more layers for fine-tuning\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "# lower learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YyeaC0AOcR9t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_finetune = model.fit(train_data_gen, epochs=20, steps_per_epoch=train_data_gen.samples // BATCH_SIZE, validation_data=val_data_gen, validation_steps=val_data_gen.samples // BATCH_SIZE,\n",
        "    callbacks=[lr_scheduler, early_stopping])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data_gen)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tBJJFnzOFpH",
        "outputId": "82dc92dc-2ffc-4b03-be0f-7224e39260e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 611ms/step - accuracy: 0.1778 - loss: 2.6089 - val_accuracy: 0.1787 - val_loss: 2.6727 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.3125 - loss: 2.4734 - val_accuracy: 0.5000 - val_loss: 2.5546 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 480ms/step - accuracy: 0.2308 - loss: 2.5076 - val_accuracy: 0.1904 - val_loss: 2.5953 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 2.4006 - val_accuracy: 0.2500 - val_loss: 2.3414 - learning_rate: 1.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 480ms/step - accuracy: 0.2586 - loss: 2.4418 - val_accuracy: 0.2451 - val_loss: 2.4414 - learning_rate: 1.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.4062 - loss: 2.3516 - val_accuracy: 0.2500 - val_loss: 2.3798 - learning_rate: 1.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 481ms/step - accuracy: 0.2791 - loss: 2.3836 - val_accuracy: 0.3076 - val_loss: 2.3236 - learning_rate: 5.0000e-06\n",
            "Epoch 8/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 2.2934 - val_accuracy: 0.5000 - val_loss: 2.2417 - learning_rate: 5.0000e-06\n",
            "Epoch 9/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 481ms/step - accuracy: 0.2802 - loss: 2.3628 - val_accuracy: 0.3340 - val_loss: 2.2682 - learning_rate: 5.0000e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.2500 - loss: 2.3740 - val_accuracy: 0.5000 - val_loss: 2.3628 - learning_rate: 5.0000e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 476ms/step - accuracy: 0.2743 - loss: 2.3532 - val_accuracy: 0.2715 - val_loss: 2.3386 - learning_rate: 2.5000e-06\n",
            "Epoch 12/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.3750 - loss: 2.4143 - val_accuracy: 0.2500 - val_loss: 2.5161 - learning_rate: 2.5000e-06\n",
            "Epoch 13/20\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 480ms/step - accuracy: 0.2830 - loss: 2.3347 - val_accuracy: 0.3047 - val_loss: 2.2951 - learning_rate: 1.2500e-06\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.3177 - loss: 2.3198\n",
            "Test Accuracy: 0.30447471141815186\n"
          ]
        }
      ]
    }
  ]
}